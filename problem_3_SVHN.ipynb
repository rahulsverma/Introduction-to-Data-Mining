{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acA76rykXveP",
        "outputId": "ed69e53c-1bcb-47cc-97c9-1da8968e82b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MtbGwcJtEQ1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gQZZYrD6BNY",
        "outputId": "c8cd0047-b01d-42c1-8695-ba85c2789f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13\n"
          ]
        }
      ],
      "source": [
        "print(13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjEUaAkjqxW-"
      },
      "outputs": [],
      "source": [
        "train_raw = loadmat('/content/train_32x32.mat')\n",
        "test_raw = loadmat('/content/test_32x32.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcSs6FtktBtj"
      },
      "outputs": [],
      "source": [
        "train_images = np.array(train_raw['X'])\n",
        "test_images = np.array(test_raw['X'])\n",
        "\n",
        "train_labels = train_raw['y']\n",
        "test_labels = test_raw['y']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vnuzvXcvE-c"
      },
      "outputs": [],
      "source": [
        "train_images = np.moveaxis(train_images, -1, 0)\n",
        "test_images = np.moveaxis(test_images, -1, 0)\n",
        "\n",
        "train_images = train_images.astype('float64')\n",
        "test_images = test_images.astype('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7Q6rMoiz_Fe"
      },
      "outputs": [],
      "source": [
        "train_labels = train_labels.astype('int64')\n",
        "test_labels = test_labels.astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-YG0829FP024"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hpu9ZF30Dyd",
        "outputId": "abee9c05-b6da-4196-a0ed-2334716a0189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min: 0.0, Max: 255.0\n"
          ]
        }
      ],
      "source": [
        "print('Min: {}, Max: {}'.format(train_images.min(), train_images.max()))\n",
        "\n",
        "train_images /= 255.0\n",
        "test_images /= 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfjLdxgh0Fyk"
      },
      "outputs": [],
      "source": [
        "lb = LabelBinarizer()\n",
        "train_labels = lb.fit_transform(train_labels)\n",
        "test_labels = lb.fit_transform(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewhYlrMv0IZV"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels,\n",
        "                                                  test_size=0.15, random_state=22)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgcS1LfO0O3k"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(rotation_range=8,\n",
        "                             zoom_range=[0.95, 1.05],\n",
        "                             height_shift_range=0.10,\n",
        "                             shear_range=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMsYUtni0pCa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "class BasicBlock(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, filter_num, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(3, 3),\n",
        "                                            strides=stride,\n",
        "                                            padding=\"same\")\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(3, 3),\n",
        "                                            strides=1,\n",
        "                                            padding=\"same\")\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        if stride != 1:\n",
        "            self.downsample = tf.keras.Sequential()\n",
        "            self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                                       kernel_size=(1, 1),\n",
        "                                                       strides=stride))\n",
        "            self.downsample.add(tf.keras.layers.BatchNormalization())\n",
        "        else:\n",
        "            self.downsample = lambda x: x\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        residual = self.downsample(inputs)\n",
        "\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "\n",
        "        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class BottleNeck(tf.keras.layers.Layer):\n",
        "    def __init__(self, filter_num, stride=1):\n",
        "        super(BottleNeck, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(1, 1),\n",
        "                                            strides=1,\n",
        "                                            padding='same')\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(3, 3),\n",
        "                                            strides=stride,\n",
        "                                            padding='same')\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters=filter_num * 4,\n",
        "                                            kernel_size=(1, 1),\n",
        "                                            strides=1,\n",
        "                                            padding='same')\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.downsample = tf.keras.Sequential()\n",
        "        self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num * 4,\n",
        "                                                   kernel_size=(1, 1),\n",
        "                                                   strides=stride))\n",
        "        self.downsample.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        residual = self.downsample(inputs)\n",
        "\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x, training=training)\n",
        "\n",
        "        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "def make_basic_block_layer(filter_num, blocks, stride=1):\n",
        "    res_block = tf.keras.Sequential()\n",
        "    res_block.add(BasicBlock(filter_num, stride=stride))\n",
        "\n",
        "    for _ in range(1, blocks):\n",
        "        res_block.add(BasicBlock(filter_num, stride=1))\n",
        "\n",
        "    return res_block\n",
        "\n",
        "\n",
        "def make_bottleneck_layer(filter_num, blocks, stride=1):\n",
        "    res_block = tf.keras.Sequential()\n",
        "    res_block.add(BottleNeck(filter_num, stride=stride))\n",
        "\n",
        "    for _ in range(1, blocks):\n",
        "        res_block.add(BottleNeck(filter_num, stride=1))\n",
        "\n",
        "    return res_block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_Y13k3H1jPm"
      },
      "outputs": [],
      "source": [
        "class ResNetTypeI(tf.keras.Model):\n",
        "    def __init__(self, layer_params):\n",
        "        super(ResNetTypeI, self).__init__()\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n",
        "                                            kernel_size=(7, 7),\n",
        "                                            strides=2,\n",
        "                                            padding=\"same\")\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                               strides=2,\n",
        "                                               padding=\"same\")\n",
        "\n",
        "        self.layer1 = make_basic_block_layer(filter_num=64,\n",
        "                                             blocks=layer_params[0])\n",
        "        self.layer2 = make_basic_block_layer(filter_num=128,\n",
        "                                             blocks=layer_params[1],\n",
        "                                             stride=2)\n",
        "        self.layer3 = make_basic_block_layer(filter_num=256,\n",
        "                                             blocks=layer_params[2],\n",
        "                                             stride=2)\n",
        "        self.layer4 = make_basic_block_layer(filter_num=512,\n",
        "                                             blocks=layer_params[3],\n",
        "                                             stride=2)\n",
        "\n",
        "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.fc = tf.keras.layers.Dense(units=10, activation=tf.keras.activations.softmax)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.layer1(x, training=training)\n",
        "        x = self.layer2(x, training=training)\n",
        "        x = self.layer3(x, training=training)\n",
        "        x = self.layer4(x, training=training)\n",
        "        x = self.avgpool(x)\n",
        "        output = self.fc(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.layer1(x, training=training)\n",
        "        x = self.layer2(x, training=training)\n",
        "        x = self.layer3(x, training=training)\n",
        "        x = self.layer4(x, training=training)\n",
        "        x = self.avgpool(x)\n",
        "        output = self.fc(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "def resnet_18():\n",
        "    return ResNetTypeI(layer_params=[2, 2, 2, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPHfTXpk1sxM"
      },
      "outputs": [],
      "source": [
        "model = resnet_18()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBlthOuj1wsq"
      },
      "outputs": [],
      "source": [
        "model.build(input_shape = (None,32,32,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olF1pfDY11Uq",
        "outputId": "35e69000-eda5-497f-adeb-efe01482c1d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"res_net_type_i\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             multiple                  9472      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  multiple                 256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  multiple                 0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 8, 8, 64)          148736    \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 4, 4, 128)         527488    \n",
            "                                                                 \n",
            " sequential_3 (Sequential)   (None, 2, 2, 256)         2103552   \n",
            "                                                                 \n",
            " sequential_5 (Sequential)   (None, 1, 1, 512)         8401408   \n",
            "                                                                 \n",
            " global_average_pooling2d (G  multiple                 0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,196,042\n",
            "Trainable params: 11,186,442\n",
            "Non-trainable params: 9,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer = \"adam\",loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCakiAQE13_G",
        "outputId": "35dc4157-9d5f-47dc-98c0-2075cce7cb7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "451/487 [==========================>...] - ETA: 2:22 - loss: 1.0447 - accuracy: 0.6595"
          ]
        }
      ],
      "source": [
        "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=128),\n",
        "                              epochs=30, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lEq91RB2D0S"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}